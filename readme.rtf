spec: 爬104職位，有「行政助理」四個字的，爬回來 存到 自己 Local DB
         存 公司名稱  職位 薪資

共三支程式 ( load_area.py , scrape104.py , area_csv_to_sql.py)，說明如下

1.  「行政助理」四個字的 精準搜索 ，須勾選 「只搜尋職務名稱」  (參數kwop=1)

2.   將 104網站的 地區 json 檔案存回 Local，篩選只有 Taiwan地區的部份，
      存成  “area.txt”  (load_area.py) 
      city,des,no
     台北市,台北市中正區,6001001001
     台北市,台北市大同區,6001001002
     台北市,台北市中山區,6001001003
     …………………………………..
     …………………………………..

3.   讀取 area.txt  依地區變數 no 及 頁數變數 建構 URL
     一次抓一頁，存 list

     將 list 轉入 dataframe , 並刪除重覆資料

   .  將 dataframe 轉存入 mysql 的 Local DB (scrape104.py)

6.  將 “area.txt” 轉入  mysql 的 Local DB  (area_csv_to_sql.py) 

7.  DBF 說明

    # 存放爬回來的資料
    use scrape_104;
    CREATE TABLE 104_for_AdminAsst (
            id INT NOT NULL AUTO_INCREMENT,       #自動產生編號
            area_no varchar(10)  NOT NULL,        #地區編號
            company_name  varchar(80) NOT NULL,   #公司名稱
            company_type  varchar(80) NOT NULL,   #公司類別
            job_name varchar(160) NOT NULL,       #職位
            salary   varchar(160) NOT NULL,       #薪資
            PRIMARY KEY(id)
            );
    
    # 存放地區資料
    use scrape_104;
    CREATE TABLE 104_area (
            area_no varchar(10)  NOT NULL,
            area_name  varchar(20) NOT NULL,
            city_name varchar(10) NOT NULL,
            PRIMARY KEY(area_no)
            );
    
    # 新增 使用 python_user'@'localhost ，供 python 程式使用，以便監控 session
    grant select, insert,update on scrape_104.104_for_AdminAsst to 'python_user'@'localhost'; 

8. 將 Table 資料輸出成 CSV 檔，截取一部份資料上傳 (輸出成excel檔.png)
9. 產生  UML sequence diagram 共三個(load_area_UML.png , scrape104_UML.png , area_csv_to_sql_UML.png)
